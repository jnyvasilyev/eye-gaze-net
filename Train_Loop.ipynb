{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWVAyg_GsMRN",
    "outputId": "fd891c81-410b-4020-df26-322a6eae0ba1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from ipdb import set_trace\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import model\n",
    "from warp import WarpImageWithFlowAndBrightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_list(json_list):\n",
    "    ldmks = [eval(s) for s in json_list]\n",
    "    return np.array([(x, y, z) for (x, y, z) in ldmks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_info(filename):\n",
    "    info_dict = {}\n",
    "    \n",
    "    # Get image data\n",
    "    img = cv2.cvtColor(cv2.imread(\"%s.jpg\" % filename[:-5]), cv2.COLOR_BGR2RGB)\n",
    "    # TODO: crop image\n",
    "    img = cv2.resize(img, (64, 32))\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    info_dict['img'] = img\n",
    "    \n",
    "\n",
    "    # Get ID data\n",
    "    titles_types = {'ID': int, 'T': str, 'N': int, 'F': int, 'V': float, 'H': float}\n",
    "    info_list = os.path.basename(filename[:-5]).split('_')\n",
    "    for title, info in zip(titles_types, info_list):\n",
    "        info_dict[title] = titles_types[title](info[len(title):])\n",
    "    info_dict['target'] = info_dict['F'] == 1\n",
    "        \n",
    "    # Get json data\n",
    "    json_data_file = open(filename)\n",
    "    json_data = json.load(json_data_file)\n",
    "    info_dict[\"look_vec\"] = np.array(eval(json_data[\"eye_details\"][\"look_vec\"])) # 3D look direction vector\n",
    "    info_dict[\"interior_margin\"] = process_json_list(json_data[\"interior_margin_2d\"]) # eye interior landmarks\n",
    "    info_dict[\"caruncle\"] = process_json_list(json_data[\"caruncle_2d\"]) # caruncle landmarks\n",
    "    info_dict[\"iris\"] = process_json_list(json_data[\"iris_2d\"]) # iris landmarks\n",
    "    \n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HvMcnkjhsU3B",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_infos = []\n",
    "input_file_path = os.path.join(os.getcwd(), '..', 'dataset', 'UnityEyes_Windows', 'imgs_1_cutouts')\n",
    "\n",
    "json_fns = glob(os.path.join(input_file_path, \"*.json\"))\n",
    "for json_fn in json_fns:\n",
    "    info = get_filename_info(json_fn)\n",
    "    img_infos.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>ID</th>\n",
       "      <th>T</th>\n",
       "      <th>N</th>\n",
       "      <th>F</th>\n",
       "      <th>V</th>\n",
       "      <th>H</th>\n",
       "      <th>target</th>\n",
       "      <th>look_vec</th>\n",
       "      <th>interior_margin</th>\n",
       "      <th>caruncle</th>\n",
       "      <th>iris</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97,...</td>\n",
       "      <td>1</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0016, 0.0, -1.0, 0.0]</td>\n",
       "      <td>[[352.8355, 265.1642, 9.0855], [349.2318, 278....</td>\n",
       "      <td>[[340.2054, 248.9607, 9.096], [333.4014, 259.0...</td>\n",
       "      <td>[[356.5728, 299.975, 8.9238], [357.405, 308.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97,...</td>\n",
       "      <td>1</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.13</td>\n",
       "      <td>4.80</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0832, -0.1068, -0.9908, 0.0]</td>\n",
       "      <td>[[352.9997, 264.6737, 9.0874], [349.6505, 277....</td>\n",
       "      <td>[[340.1695, 248.8329, 9.0979], [333.4014, 259....</td>\n",
       "      <td>[[363.3105, 290.1617, 8.8879], [363.9812, 298....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97,...</td>\n",
       "      <td>1</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.77</td>\n",
       "      <td>10.84</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.1874, 0.0831, -0.9788, 0.0]</td>\n",
       "      <td>[[352.6367, 265.7174, 9.0836], [348.7342, 279....</td>\n",
       "      <td>[[340.2437, 249.1077, 9.094], [333.4014, 259.0...</td>\n",
       "      <td>[[372.4717, 303.7707, 8.8355], [372.5953, 312....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97,...</td>\n",
       "      <td>1</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-13.43</td>\n",
       "      <td>-5.19</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.088, -0.2322, -0.9687, 0.0]</td>\n",
       "      <td>[[353.3353, 263.5461, 9.0922], [350.5352, 276....</td>\n",
       "      <td>[[340.0798, 248.548, 9.1021], [333.4014, 259.0...</td>\n",
       "      <td>[[349.5125, 282.5456, 9.007], [350.4209, 290.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97,...</td>\n",
       "      <td>1</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.65</td>\n",
       "      <td>9.39</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.1603, -0.1848, -0.9696, 0.0]</td>\n",
       "      <td>[[353.2023, 264.0168, 9.0901], [350.1789, 276....</td>\n",
       "      <td>[[340.1184, 248.6655, 9.1004], [333.4014, 259....</td>\n",
       "      <td>[[369.9451, 282.7769, 8.8686], [370.5723, 291....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img  ID         T  N  F  \\\n",
       "0  [[[97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97,...   1  gaussian  1  1   \n",
       "1  [[[97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97,...   1  gaussian  1  2   \n",
       "2  [[[97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97,...   1  gaussian  1  3   \n",
       "3  [[[97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97,...   1  gaussian  1  4   \n",
       "4  [[[97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97,...   1  gaussian  1  5   \n",
       "\n",
       "       V      H  target                         look_vec  \\\n",
       "0   0.00   0.09    True         [0.0016, 0.0, -1.0, 0.0]   \n",
       "1  -6.13   4.80   False  [0.0832, -0.1068, -0.9908, 0.0]   \n",
       "2   4.77  10.84   False   [0.1874, 0.0831, -0.9788, 0.0]   \n",
       "3 -13.43  -5.19   False  [-0.088, -0.2322, -0.9687, 0.0]   \n",
       "4 -10.65   9.39   False  [0.1603, -0.1848, -0.9696, 0.0]   \n",
       "\n",
       "                                     interior_margin  \\\n",
       "0  [[352.8355, 265.1642, 9.0855], [349.2318, 278....   \n",
       "1  [[352.9997, 264.6737, 9.0874], [349.6505, 277....   \n",
       "2  [[352.6367, 265.7174, 9.0836], [348.7342, 279....   \n",
       "3  [[353.3353, 263.5461, 9.0922], [350.5352, 276....   \n",
       "4  [[353.2023, 264.0168, 9.0901], [350.1789, 276....   \n",
       "\n",
       "                                            caruncle  \\\n",
       "0  [[340.2054, 248.9607, 9.096], [333.4014, 259.0...   \n",
       "1  [[340.1695, 248.8329, 9.0979], [333.4014, 259....   \n",
       "2  [[340.2437, 249.1077, 9.094], [333.4014, 259.0...   \n",
       "3  [[340.0798, 248.548, 9.1021], [333.4014, 259.0...   \n",
       "4  [[340.1184, 248.6655, 9.1004], [333.4014, 259....   \n",
       "\n",
       "                                                iris  \n",
       "0  [[356.5728, 299.975, 8.9238], [357.405, 308.47...  \n",
       "1  [[363.3105, 290.1617, 8.8879], [363.9812, 298....  \n",
       "2  [[372.4717, 303.7707, 8.8355], [372.5953, 312....  \n",
       "3  [[349.5125, 282.5456, 9.007], [350.4209, 290.7...  \n",
       "4  [[369.9451, 282.7769, 8.8686], [370.5723, 291....  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_df = pd.DataFrame(img_infos)\n",
    "img_df.sort_values(['ID', 'F'], ignore_index=True, inplace=True)\n",
    "img_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on the dataframe info\n",
    "- look_vec is a 3D homogeneous vector in the form \\[x, y, z, 0\\]. For purposes of the model input, only the x and y components are needed. I believe this vector is already normalized, but we can renormalize this vector before extracting the x and y components\n",
    "- Feature landmarks (i.e., interior_margin, caruncle, and iris) are the pixel coordinates of feature BEFORE RESIZING. Ideally they are used to determine the crop/resize area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0832 -0.1068 -0.9908  0.    ]\n",
      " [ 0.1874  0.0831 -0.9788  0.    ]\n",
      " [-0.088  -0.2322 -0.9687  0.    ]\n",
      " ...\n",
      " [ 0.0298  0.2497 -0.9679  0.    ]\n",
      " [ 0.0052 -0.0496 -0.9988  0.    ]\n",
      " [-0.0889 -0.0946 -0.9915  0.    ]]\n",
      "[[ 0.08319945 -0.1067993 ]\n",
      " [ 0.18739308  0.08309693]\n",
      " [-0.08799822 -0.23219529]\n",
      " ...\n",
      " [ 0.02979898  0.24969144]\n",
      " [ 0.00519977 -0.0495978 ]\n",
      " [-0.08890335 -0.09460357]]\n"
     ]
    }
   ],
   "source": [
    "X_img = np.stack(img_df.query('target == False')['img'])\n",
    "# X_angle = img_df.query('target == False')[['H', 'V']].to_numpy()\n",
    "# Get x and y components of look_vec\n",
    "X_angle = np.stack(img_df.query('target == False')['look_vec'].to_numpy())\n",
    "X_angle = (X_angle / np.linalg.norm(X_angle, axis=1, keepdims=True))[:, :2] # normalize, then get x and y components\n",
    "X_angle = np.tile(X_angle[:, :, np.newaxis, np.newaxis], (1, 1, 32, 64))\n",
    "y = np.stack(img_df.query('target == True')['img'])\n",
    "y = np.repeat(y, 39, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fmonNWBAs_Dk"
   },
   "outputs": [],
   "source": [
    "num_samples = X_img.shape[0]\n",
    "splits = [0.7, 0.2, 0.1]\n",
    "\n",
    "X_img_train, X_img_valid, X_img_test = np.split(X_img, [int(num_samples * splits[0]), int(num_samples * (splits[0] + splits[1]))])\n",
    "X_angle_train, X_angle_valid, X_angle_test = np.split(X_angle, [int(num_samples * splits[0]), int(num_samples * (splits[0] + splits[1]))])\n",
    "y_train, y_valid, y_test = np.split(y, [int(num_samples * splits[0]), int(num_samples * (splits[0] + splits[1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Cb-oRNU8v8Ik"
   },
   "outputs": [],
   "source": [
    "X_img_train = torch.tensor(X_img_train, dtype=torch.int)\n",
    "X_angle_train = torch.tensor(X_angle_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.int)\n",
    "\n",
    "X_img_valid = torch.tensor(X_img_valid, dtype=torch.int)\n",
    "X_angle_valid = torch.tensor(X_angle_valid, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.int)\n",
    "\n",
    "X_img_test = torch.tensor(X_img_test, dtype=torch.int)\n",
    "X_angle_test = torch.tensor(X_angle_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Uu2HyXd7wgn7"
   },
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "train_dataset = TensorDataset(X_img_train, X_angle_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataset = TensorDataset(X_img_valid, X_angle_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataset = TensorDataset(X_img_test, X_angle_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–‰                                                                                          | 1/100 [00:30<50:35, 30.67s/it, TLoss=14452.201, VLoss=1874.373]"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "weight_correction_loss = 0.8\n",
    "weight_reconstruction_loss = 0.2\n",
    "\n",
    "printout_freq = 1\n",
    "start_time = time.time()\n",
    "\n",
    "warp = WarpImageWithFlowAndBrightness(next(iter(train_loader))[0])\n",
    "\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "pbar = tqdm(range(num_epochs))\n",
    "for epoch in pbar:\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for imgs, angles, targets in train_loader:\n",
    "        imgs, angles, targets = imgs.float().to(device), angles.to(device), targets.float().to(device)\n",
    "        \n",
    "        flow_corr, bright_corr = model(imgs, angles)\n",
    "        img_corr = warp(imgs, flow_corr, bright_corr)\n",
    "        loss_correction = criterion(img_corr, targets)\n",
    "        \n",
    "        inverted_angles = -angles\n",
    "        flow_reconstruction, bright_reconstruction = model(img_corr, inverted_angles)\n",
    "        img_reconstruction = warp(img_corr, flow_reconstruction, bright_reconstruction)\n",
    "        loss_reconstruction = criterion(img_reconstruction, imgs)\n",
    "        \n",
    "        loss = (weight_correction_loss * loss_correction) + (weight_reconstruction_loss) * loss_reconstruction\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0\n",
    "        for imgs, angles, targets in valid_loader:\n",
    "            imgs, angles, targets = imgs.float().to(device), angles.to(device), targets.float().to(device)\n",
    "\n",
    "            flow_corr, bright_corr = model(imgs, angles)\n",
    "            img_corr = warp(imgs, flow_corr, bright_corr)\n",
    "            loss_correction = criterion(img_corr, targets)\n",
    "\n",
    "            inverted_angles = -angles\n",
    "            flow_reconstruction, bright_reconstruction = model(img_corr, inverted_angles)\n",
    "            img_reconstruction = warp(img_corr, flow_reconstruction, bright_reconstruction)\n",
    "            loss_reconstruction = criterion(img_reconstruction, imgs)\n",
    "\n",
    "            loss = (weight_correction_loss * loss_correction) + (weight_reconstruction_loss) * loss_reconstruction\n",
    "            valid_loss += loss.item()\n",
    "        valid_losses.append(valid_loss / len(valid_loader))\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    overall_time = time.time() - start_time\n",
    "    num_days = int(overall_time / 86400)\n",
    "    num_hrs = int((overall_time-(86400*num_days)) / 3600)\n",
    "    num_mins = int((overall_time-(86400*num_days)-(3600*num_hrs)) / 60)\n",
    "    num_secs = overall_time-(86400*num_days)-(3600*num_hrs)*(60*num_mins)\n",
    "    if (epoch + 1) % printout_freq == 0:\n",
    "    #     print(f\"\"\"Finished epoch {epoch + 1}/{num_epochs} ({(epoch+1)/num_epochs*100:.2f}%)\n",
    "    #            total time is {num_days}d:{num_hrs}h:{num_mins}m:{num_secs:.3f}s; time for this epoch is {epoch_time:.2f}s\n",
    "    #            training loss was {bcolors.BOLD}{train_loss:.3f}{bcolors.ENDC}, validation_loss was {bcolors.BOLD}{valid_loss:.3f}{bcolors.ENDC}.\"\"\")\n",
    "        pbar.set_postfix({\"TLoss\": f\"{train_loss:.3f}\", \"VLoss\": f\"{valid_loss:.3f}\"})\n",
    "\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, angles, targets in test_loader:\n",
    "        imgs, angles, targets = imgs.float().to(device), angles.to(device), targets.float().to(device)\n",
    "\n",
    "        flow_corr, bright_corr = model(imgs, angles)\n",
    "        img_corr = warp(imgs, flow_corr, bright_corr)\n",
    "        loss_correction = criterion(img_corr, targets)\n",
    "        \n",
    "        inverted_angles = -angles\n",
    "        flow_reconstruction, bright_reconstruction = model(img_corr, inverted_angles)\n",
    "        img_reconstruction = warp(img_corr, flow_reconstruction, bright_reconstruction)\n",
    "        loss_reconstruction = criterion(img_reconstruction, imgs)\n",
    "        \n",
    "        loss = (weight_correction_loss * loss_correction) + (weight_reconstruction_loss) * loss_reconstruction\n",
    "        test_loss += loss.item()\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
